{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e37ff010-3728-42c0-afca-c006a9450947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 전처리 및 파생컬럼 추가 할거, 이상치 결측치는 확인해보고,(flight_arrival 맥스값이 0이 떳었는데 확인해보기)\n",
    "#파생컬럼 -> 데이터 설명 다시 들어가보고, \n",
    "# 1.분기 반기 혹은 연도별 시간대 비율 \n",
    "# 2.항공편 비율과 승객 비율 해서 한 비행기당 사람 얼마나 타는지 비율 생성 후 혼잡도와 비교? -> 이를 통해 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03323c74-f9bd-4f82-8d3b-2e739ba9abd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 시간대별 데이터 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff7eae4d-f7b6-4d78-971a-c6ee07fcc597",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#읽기\n",
    "df_hourly = spark.table(\"`1team-postgresql-connection_catalog`.bronze.bronze_hourly_202307_202506\")\n",
    "display(df_hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4bac1ab-d400-4b62-95c0-12a03474e323",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 중복제거\n",
    "\n",
    "df_hourly = df_hourly.dropDuplicates()\n",
    "\n",
    "# 결과 확인\n",
    "df_hourly.printSchema()\n",
    "display(df_hourly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "362e7647-16a3-4691-93f9-65c0204f9b9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 0. 월별(연,월) 윈도우 정의\n",
    "w_month = Window.partitionBy(\"year\", \"month\")\n",
    "\n",
    "# 1. 항공편당 평균 승객 수\n",
    "df_hourly = df_hourly.withColumn(\n",
    "    \"avg_passenger_per_flight\",\n",
    "    F.col(\"passenger_total\") / F.col(\"flight_total\")\n",
    ")\n",
    "\n",
    "# 2. 항공편당 평균 화물량\n",
    "df_hourly = df_hourly.withColumn(\n",
    "    \"avg_cargo_per_flight\",\n",
    "    F.col(\"cargo_total\") / F.col(\"flight_total\")\n",
    ")\n",
    "\n",
    "# 3. 시간대별 혼잡도 지표 (월평균 대비)\n",
    "df_hourly = df_hourly.withColumn(\n",
    "    \"month_flight_total_mean\",\n",
    "    F.avg(\"flight_total\").over(w_month)\n",
    ").withColumn(\n",
    "    \"congestion_index\",\n",
    "    F.col(\"flight_total\") / F.col(\"month_flight_total_mean\")\n",
    ").drop(\"month_flight_total_mean\")\n",
    "\n",
    "# 4. 시간대별 점유율 (월 전체 대비)\n",
    "df_hourly = df_hourly.withColumn(\n",
    "    \"month_flight_total_sum\",\n",
    "    F.sum(\"flight_total\").over(w_month)\n",
    ").withColumn(\n",
    "    \"flight_share\",\n",
    "    F.col(\"flight_total\") / F.col(\"month_flight_total_sum\")\n",
    ").drop(\"month_flight_total_sum\")\n",
    "\n",
    "# 5. 피크타임 태깅 (월별 상위 20% 혼잡 시간대)\n",
    "w_rank = Window.partitionBy(\"year\", \"month\").orderBy(F.desc(\"congestion_index\"))\n",
    "df_hourly = df_hourly.withColumn(\n",
    "    \"rank_in_month\",\n",
    "    F.row_number().over(w_rank)\n",
    ")\n",
    "df_hourly = df_hourly.withColumn(\n",
    "    \"month_count\",\n",
    "    F.count(\"*\").over(w_month)\n",
    ")\n",
    "df_hourly = df_hourly.withColumn(\n",
    "    \"peak_time_flag\",\n",
    "    F.when(F.col(\"rank_in_month\") <= (F.col(\"month_count\") * 0.2), 1).otherwise(0)\n",
    ").drop(\"rank_in_month\", \"month_count\")\n",
    "\n",
    "# 6. year, month 컬럼을 int 타입으로 변환 (정렬 문제 방지)\n",
    "df_hourly = df_hourly.withColumn(\"year\", F.col(\"year\").cast(\"int\"))\n",
    "df_hourly = df_hourly.withColumn(\"month\", F.col(\"month\").cast(\"int\"))\n",
    "\n",
    "# 결과 확인\n",
    "df_hourly.printSchema()\n",
    "display(df_hourly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40fb15d3-c208-4e2a-94dd-1397a08508a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 코드 단계별 설명\n",
    "\n",
    "#### 0. 월별(연,월) 윈도우 정의\n",
    "- 연도, 월별로 그룹화 기준 만듦  \n",
    "- 월 단위 집계(평균, 합계 등)용\n",
    "\n",
    "#### 1. 항공편당 평균 승객 수\n",
    "- avg_passenger_per_flight 컬럼 추가  \n",
    "- 계산: passenger_total ÷ flight_total  \n",
    "- 항공편 1대당 평균 승객 수\n",
    "\n",
    "#### 2. 항공편당 평균 화물량\n",
    "- avg_cargo_per_flight 컬럼 추가  \n",
    "- 계산: cargo_total ÷ flight_total  \n",
    "- 항공편 1대당 평균 화물량\n",
    "\n",
    "#### 3. 시간대별 혼잡도 지표 (월평균 대비)\n",
    "- congestion_index 컬럼 추가  \n",
    "- 계산: flight_total ÷ (월평균 flight_total)  \n",
    "- 1보다 크면 혼잡, 1보다 작으면 덜 혼잡\n",
    "\n",
    "#### 4. 시간대별 점유율 (월 전체 대비)\n",
    "- flight_share 컬럼 추가  \n",
    "- 계산: flight_total ÷ (월 전체 flight_total 합계)  \n",
    "- 월 전체에서 해당 시간대가 차지하는 비중\n",
    "\n",
    "#### 5. 피크타임 태깅 (월별 상위 20% 혼잡 시간대)\n",
    "- peak_time_flag 컬럼 추가  \n",
    "- 혼잡도 상위 20%면 1, 아니면 0  \n",
    "- 월별로 가장 붐비는 시간대 자동 태깅\n",
    "\n",
    "#### 6. 컬럼 타입 정리 (연, 월을 문자열로) <- 이거했다가 정렬 지맘대로 돼서 다시 처음부터 불러오는중 ㅠㅠ\n",
    "- year, month 컬럼 string 타입으로 변환  \n",
    "- 데이터 타입 통일 및 활용성↑\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16d65a71-74b6-48ea-8ae4-9f2e7f4ff4c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 결측치 이상치 처리중 + 이름변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5276870-f3a7-45e6-94dc-beedc2f81e38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 이름 변경 (혼동 방지) 처음부터 hourly로 불러와서 안해도 된다.\n",
    "#df_hourly = df_bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bea2c66-545d-4d50-8045-1fde1c410ddc",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1752041797303}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d21fbfbe-4366-4d2f-be67-4037f403659e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 결측치확인\n",
    "num_cols = [\n",
    "    'flight_arrival', 'flight_departure', 'flight_total',\n",
    "    'passenger_arrival', 'passenger_departure', 'passenger_total',\n",
    "    'cargo_arrival', 'cargo_departure', 'cargo_total'\n",
    "]\n",
    "\n",
    "for col in num_cols:\n",
    "    print(f\"{col}: {df_hourly.filter(df_hourly[col].isNull()).count()}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "659da755-27e0-42c5-982b-63134c9374a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#이상치 탐지\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "num_cols = [\n",
    "    'flight_arrival', 'flight_departure', 'flight_total',\n",
    "    'passenger_arrival', 'passenger_departure', 'passenger_total',\n",
    "    'cargo_arrival', 'cargo_departure', 'cargo_total'\n",
    "]\n",
    "\n",
    "for col in num_cols:\n",
    "   \n",
    "    quantiles = df_hourly.approxQuantile(col, [0.25, 0.75], 0.01)\n",
    "    Q1, Q3 = quantiles\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "    # 이상치 플래그 컬럼 추가 (True면 이상치)\n",
    "    df_hourly = df_hourly.withColumn(\n",
    "        f\"{col}_outlier_flag\",\n",
    "        (F.col(col) < lower) | (F.col(col) > upper)\n",
    "    )\n",
    "\n",
    "# 결과 확인\n",
    "df_hourly.printSchema()\n",
    "display(df_hourly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9fdf2e96-6868-41a5-aab0-068d2a4631af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 이상치 플래그가 True인 row만 추출\n",
    "\n",
    "# 이상치 플래그 컬럼 리스트\n",
    "outlier_flags = [\n",
    "    'flight_arrival_outlier_flag',\n",
    "    'flight_departure_outlier_flag',\n",
    "    'flight_total_outlier_flag',\n",
    "    'passenger_arrival_outlier_flag',\n",
    "    'passenger_departure_outlier_flag',\n",
    "    'passenger_total_outlier_flag',\n",
    "    'cargo_arrival_outlier_flag',\n",
    "    'cargo_departure_outlier_flag',\n",
    "    'cargo_total_outlier_flag'\n",
    "]\n",
    "\n",
    "# 여러 플래그 중 하나라도 True인 row만 필터링\n",
    "from functools import reduce\n",
    "\n",
    "condition = reduce(lambda a, b: a | b, [F.col(f) for f in outlier_flags])\n",
    "df_outliers = df_hourly.filter(condition)\n",
    "\n",
    "# 결과 확인\n",
    "display(df_outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f2f98c3-a9d3-4b85-bd8d-ae57bea3faff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " 이상치(Outlier) 분석 요약\n",
    "\n",
    "- **이상치 발생 구간**\n",
    "  - 주로 **23시-00시**와 **03시-04시** 시간대에서 반복적으로 이상치 발생\n",
    "  - 연도와 월이 달라도 동일 시간대에서 일관되게 나타남\n",
    "\n",
    "- **이상치 특징**\n",
    "  - **화물 출발량**(cargo_departure)에서 전체 이동량 대비 큰 차이로 이상치 탐지\n",
    "  - **항공편**과 **승객** 관련 데이터는 분포가 안정적이며, 이상치가 거의 없음\n",
    "\n",
    "- **원인 추정 및 실무적 판단**\n",
    "  - 특정 이벤트(예: 연휴, 사고 등)보다는 **야간 집중 출고** 등 운영 패턴의 영향일 가능성이 높음\n",
    "  - 본 프로젝트에서 **화물 데이터는 핵심 분석 요인이 아니므로, 해당 이상치는 무시해도 무방**하다고 판단\n",
    "\n",
    "---\n",
    "\n",
    "> **정리:**  \n",
    "> 반복적으로 탐지되는 화물 출발 이상치는 야간 운영 특성에 의한 것으로 보이며,  \n",
    "> 프로젝트 목적상 분석 및 서비스에는 큰 영향이 없으므로 별도 조치 없이 진행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df93ae1b-4ba9-4d27-8c12-8da32e3dbed0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 이상치 플래그 컬럼 일괄 삭제 코드 (PySpark)\n",
    "\n",
    "# 삭제할 컬럼명 리스트\n",
    "outlier_flags = [\n",
    "    'flight_arrival_outlier_flag',\n",
    "    'flight_departure_outlier_flag',\n",
    "    'flight_total_outlier_flag',\n",
    "    'passenger_arrival_outlier_flag',\n",
    "    'passenger_departure_outlier_flag',\n",
    "    'passenger_total_outlier_flag',\n",
    "    'cargo_arrival_outlier_flag',\n",
    "    'cargo_departure_outlier_flag',\n",
    "    'cargo_total_outlier_flag'\n",
    "]\n",
    "\n",
    "# DataFrame에서 해당 컬럼들 삭제\n",
    "df_hourly = df_hourly.drop(*outlier_flags)\n",
    "\n",
    "# 결과 확인\n",
    "df_hourly.printSchema()\n",
    "display(df_hourly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cbfe7c8-5213-4134-89a3-bc7f7bf010b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96d3c293-7966-4726-b96e-9f71cafff5e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# year, month 컬럼을 정수(int) 타입으로 변환 (PySpark)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_hourly = df_hourly \\\n",
    "    .withColumn(\"year\", F.col(\"year\").cast(\"int\")) \\\n",
    "    .withColumn(\"month\", F.col(\"month\").cast(\"int\"))\n",
    "\n",
    "# 결과 확인\n",
    "df_hourly.printSchema()\n",
    "display(df_hourly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7092ab8-5b0a-417f-b838-777425f9c28c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 시간대 00시-01시에서 00시 01시 17시 이런식으료 변경 + 파생컬럼 추가 및 순서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce751219-3ca2-4f73-b8cc-70b455e76812",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"month\":106},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1752041306610}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 시간대 문자열 → 정수형 hour_of_day 컬럼 추가 (PySpark)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 예시: \"00시-01시\" → 0, \"04시-05시\" → 4, ..., \"23시-00시\" → 23\n",
    "df_hourly = df_hourly.withColumn(\n",
    "    \"hour_of_day\",\n",
    "    F.regexp_extract(\"time_slot\", r\"^(\\d{2})시\", 1).cast(\"int\")\n",
    ")\n",
    "\n",
    "# 컬럼 순서 재정렬: year, month, time_slot, hour_of_day, flight_arrival, ...\n",
    "cols = df_hourly.columns\n",
    "# time_slot 다음에 hour_of_day 삽입\n",
    "idx = cols.index(\"time_slot\") + 1\n",
    "new_cols = cols[:idx] + [\"hour_of_day\"] + cols[idx:]\n",
    "df_hourly = df_hourly.select(*new_cols)\n",
    "\n",
    "# 결과 확인\n",
    "df_hourly.printSchema()\n",
    "display(df_hourly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bae8b862-96d1-464c-9e8f-b47aa722213f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#아니 정수로 하면 된다면서!!! 텍스트 ㅁ라고!!!!!1 너무하네 증말\n",
    "# 와드디어 됐다!!!!!!!!!!!!!!!!!!!!! 이거 하나 하는데 뭔 시간을 땅에 다 버렸네\n",
    "df_hourly = df_hourly.orderBy(\"year\", \"month\", \"hour_of_day\")\n",
    "display(df_hourly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1648595-c8ab-4b36-9190-c7f65d244cea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_hourly.printSchema()\n",
    "#아니 왜 hopur_of_day 두개임? 복제야????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf35bd68-8a7d-4a72-b2e1-f2815feb1e3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# hour_of_day 컬럼이 중복되어 있을 때, 맨 뒤 hour_of_day 컬럼만 삭제\n",
    "\n",
    "# 1. 컬럼 리스트에서 hour_of_day가 등장하는 인덱스 찾기\n",
    "cols = df_hourly.columns\n",
    "\n",
    "# 2. hour_of_day가 여러 번 있으면 마지막 인덱스만 제거\n",
    "if cols.count(\"hour_of_day\") > 1:\n",
    "    # 마지막 hour_of_day의 인덱스 찾기\n",
    "    last_idx = len(cols) - 1 - cols[::-1].index(\"hour_of_day\")\n",
    "    # 마지막 hour_of_day만 제외한 컬럼 리스트 생성\n",
    "    new_cols = [col for i, col in enumerate(cols) if i != last_idx]\n",
    "    # DataFrame 재구성\n",
    "    df_hourly = df_hourly.select(*new_cols)\n",
    "\n",
    "# 결과 확인\n",
    "df_hourly.printSchema()\n",
    "display(df_hourly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f13110a-cd88-4408-866b-54fd12404274",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. day 컬럼 추가 (모든 row에 1로 세팅, int 타입)\n",
    "df_hourly = df_hourly.withColumn(\"day\", F.lit(1).cast(\"int\"))\n",
    "\n",
    "# 2. date 컬럼 추가 (year, month, day를 합쳐서 'yyyymmdd' 형태의 문자열로, varchar 타입)\n",
    "df_hourly = df_hourly.withColumn(\n",
    "    \"date\",\n",
    "    F.concat_ws(\n",
    "        \"\",\n",
    "        F.format_string(\"%04d\", F.col(\"year\")),\n",
    "        F.format_string(\"%02d\", F.col(\"month\")),\n",
    "        F.format_string(\"%02d\", F.col(\"day\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# 결과 확인\n",
    "df_hourly.printSchema()\n",
    "display(df_hourly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d06a4ff0-6cf4-49f6-a2df-3c356729880f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 원하는 컬럼 순서대로 재정렬 (PySpark 예시)\n",
    "\n",
    "# 1. 원하는 컬럼 순서 리스트\n",
    "cols_order = [\n",
    "    \"date\",          # 1. 날짜 (yyyymmdd)\n",
    "    \"year\",          # 2. 연도\n",
    "    \"month\",         # 3. 월\n",
    "    \"day\",           # 4. 일\n",
    "    \"time_slot\",     # 5. 시간대 문자열\n",
    "    \"hour_of_day\",   # 6. 시간대(정수)\n",
    "    \"flight_arrival\",\n",
    "    \"flight_departure\",\n",
    "    \"flight_total\",\n",
    "    \"passenger_arrival\",\n",
    "    \"passenger_departure\",\n",
    "    \"passenger_total\",\n",
    "    \"cargo_arrival\",\n",
    "    \"cargo_departure\",\n",
    "    \"cargo_total\",\n",
    "    \"avg_passenger_per_flight\",\n",
    "    \"avg_cargo_per_flight\",\n",
    "    \"congestion_index\",\n",
    "    \"flight_share\",\n",
    "    \"peak_time_flag\"\n",
    "]\n",
    "\n",
    "# 2. DataFrame 컬럼 순서 재정렬\n",
    "df_hourly = df_hourly.select(*cols_order)\n",
    "\n",
    "# 결과 확인\n",
    "df_hourly.printSchema()\n",
    "display(df_hourly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa8970fd-5423-452d-87a0-402fe439799a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_hourly.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://1dt-2nd-team1-postgres.postgres.database.azure.com:5432/postgres\") \\\n",
    "    .option(\"dbtable\", \"silver.silver_hourly_202307_202506\") \\\n",
    "    .option(\"user\", \"azureuser\") \\\n",
    "    .option(\"password\", \"asdASD123!@#\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"sslmode\", \"require\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3114eaac-1ce1-4209-88b5-130b7eddda34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 월별 데이터 정리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad292af0-9128-452b-87cf-6d866cbfecd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_monthly = spark.table(\"`1team-postgresql-connection_catalog`.bronze.bronze_monthly_202307_202506\")\n",
    "display(df_monthly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e385ac9-ac66-43e4-afd2-7301fd527056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 0. 연도별 윈도우 정의 (연간 합계, 순위 등 계산용)\n",
    "w_year = Window.partitionBy(\"year\").orderBy(F.desc(\"flight_total\"))\n",
    "w_year_sum = Window.partitionBy(\"year\")\n",
    "\n",
    "# 1. 항공편당 평균 승객 수\n",
    "df_monthly = df_monthly.withColumn(\n",
    "    \"avg_passenger_per_flight\",\n",
    "    F.col(\"passenger_total\") / F.col(\"flight_total\")\n",
    ")\n",
    "\n",
    "# 3. 전월 대비 증감률 (flight_total, passenger_total, cargo_total)\n",
    "w_month = Window.orderBy(\"year\", \"month\")\n",
    "for col in [\"flight_total\", \"passenger_total\", \"cargo_total\"]:\n",
    "    df_monthly = df_monthly.withColumn(\n",
    "        f\"{col}_prev_month\",\n",
    "        F.lag(col).over(w_month)\n",
    "    ).withColumn(\n",
    "        f\"{col}_mom_growth\",\n",
    "        (F.col(col) - F.col(f\"{col}_prev_month\")) / F.col(f\"{col}_prev_month\")\n",
    "    )\n",
    "\n",
    "# 4. 전년 동월 대비 증감률 (flight_total, passenger_total, cargo_total)\n",
    "for col in [\"flight_total\", \"passenger_total\", \"cargo_total\"]:\n",
    "    df_monthly = df_monthly.withColumn(\n",
    "        f\"{col}_prev_year\",\n",
    "        F.lag(col, 12).over(w_month)\n",
    "    ).withColumn(\n",
    "        f\"{col}_yoy_growth\",\n",
    "        (F.col(col) - F.col(f\"{col}_prev_year\")) / F.col(f\"{col}_prev_year\")\n",
    "    )\n",
    "\n",
    "# 5. 피크 시즌 태깅 (연간 flight_total 상위 20%)\n",
    "df_monthly = df_monthly.withColumn(\n",
    "    \"rank_in_year\",\n",
    "    F.row_number().over(w_year)\n",
    ")\n",
    "df_monthly = df_monthly.withColumn(\n",
    "    \"year_count\",\n",
    "    F.count(\"*\").over(w_year_sum)\n",
    ")\n",
    "df_monthly = df_monthly.withColumn(\n",
    "    \"peak_month_flag\",\n",
    "    F.when(F.col(\"rank_in_year\") <= (F.col(\"year_count\") * 0.2), 1).otherwise(0)\n",
    ").drop(\"rank_in_year\", \"year_count\")\n",
    "\n",
    "# 6. 이동량 점유율 (연간 flight_total 대비 월별 flight_total 비중)\n",
    "df_monthly = df_monthly.withColumn(\n",
    "    \"year_flight_total_sum\",\n",
    "    F.sum(\"flight_total\").over(w_year_sum)\n",
    ").withColumn(\n",
    "    \"month_flight_share\",\n",
    "    F.col(\"flight_total\") / F.col(\"year_flight_total_sum\")\n",
    ").drop(\"year_flight_total_sum\")\n",
    "\n",
    "# 결과 확인\n",
    "df_monthly.printSchema()\n",
    "display(df_monthly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f3c16c4-1a22-4744-9d91-290c1286b704",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 월(month) 컬럼 정렬 문제 해결: 반드시 정렬(orderBy) 명시!\n",
    "\n",
    "# 1. 월 컬럼이 숫자(int) 타입인지 확인 후, 아니라면 int로 변환\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_monthly = df_monthly.withColumn(\"month\", F.col(\"month\").cast(\"int\"))\n",
    "\n",
    "# 2. 연도-월 기준으로 정렬 (시간 순서대로)\n",
    "df_monthly = df_monthly.orderBy(\"year\", \"month\")\n",
    "\n",
    "# 3. 결과 확인\n",
    "display(df_monthly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46b79a2a-c764-4e95-af36-79eb73ae76fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "결측치는 존재, 전년/전월대비 여서 결측 존재."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbcc7193-61fd-4f93-a444-a3d9dec32865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 월별 집계 데이터 파생 컬럼 설명\n",
    "\n",
    "#### avg_passenger_per_flight\n",
    "- 항공편 1대당 평균 승객 수  \n",
    "- 계산: passenger_total ÷ flight_total  \n",
    "- 항공편 효율성 및 혼잡도 추이 파악\n",
    "\n",
    "#### flight_total_mom_growth / passenger_total_mom_growth / cargo_total_mom_growth\n",
    "- 전월 대비 항공편, 승객, 화물 증감률  \n",
    "- 계산: (이번달 값 - 전월 값) ÷ 전월 값  \n",
    "- 월별 이동량 변화, 급증/급감 시점 탐지\n",
    "\n",
    "#### flight_total_yoy_growth / passenger_total_yoy_growth / cargo_total_yoy_growth\n",
    "- 전년 동월 대비 항공편, 승객, 화물 증감률  \n",
    "- 계산: (이번달 값 - 전년 동월 값) ÷ 전년 동월 값  \n",
    "- 계절성, 연간 성장/감소 트렌드 분석\n",
    "\n",
    "#### peak_month_flag\n",
    "- 연간 항공편 수 기준 상위 20% 달이면 1, 아니면 0  \n",
    "- 연중 이동량 집중(피크 시즌) 자동 식별\n",
    "\n",
    "#### month_flight_share\n",
    "- 해당 월의 항공편 수가 연간 전체에서 차지하는 비중  \n",
    "- 계산: flight_total ÷ (연간 flight_total 합계)  \n",
    "- 연간 이동량 중 월별 중요도 비교\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a623e266-d56c-4795-b4f3-656152ce26db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. day 컬럼 추가 (항상 1, int 타입)\n",
    "df_monthly = df_monthly.withColumn(\"day\", F.lit(1).cast(\"int\"))\n",
    "\n",
    "# 2. date 컬럼 추가 (year, month, day를 int로 변환 후 'yyyymmdd' 문자열 생성)\n",
    "df_monthly = df_monthly.withColumn(\n",
    "    \"date\",\n",
    "    F.concat_ws(\n",
    "        \"\",\n",
    "        F.format_string(\"%04d\", F.col(\"year\").cast(\"int\")),\n",
    "        F.format_string(\"%02d\", F.col(\"month\").cast(\"int\")),\n",
    "        F.format_string(\"%02d\", F.col(\"day\").cast(\"int\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. 원하는 컬럼 순서로 재정렬 (예시, 실제 컬럼명에 맞게 조정)\n",
    "cols_order = [\n",
    "    \"date\", \"year\", \"month\", \"day\",\n",
    "    \"flight_arrival\", \"flight_departure\", \"flight_total\",\n",
    "    \"passenger_arrival\", \"passenger_departure\", \"passenger_total\",\n",
    "    \"cargo_arrival\", \"cargo_departure\", \"cargo_total\",\n",
    "    \"avg_passenger_per_flight\",\n",
    "    \"flight_total_prev_month\", \"flight_total_mom_growth\",\n",
    "    \"passenger_total_prev_month\", \"passenger_total_mom_growth\",\n",
    "    \"cargo_total_prev_month\", \"cargo_total_mom_growth\",\n",
    "    \"flight_total_prev_year\", \"flight_total_yoy_growth\",\n",
    "    \"passenger_total_prev_year\", \"passenger_total_yoy_growth\",\n",
    "    \"cargo_total_prev_year\", \"cargo_total_yoy_growth\",\n",
    "    \"peak_month_flag\", \"month_flight_share\"\n",
    "]\n",
    "\n",
    "df_monthly = df_monthly.select(*cols_order)\n",
    "\n",
    "# 결과 확인\n",
    "df_monthly.printSchema()\n",
    "display(df_monthly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2efb4994-9f5c-47cd-ad7d-075aafed7cc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 각 컬럼별 NULL 개수 집계 (monthly DataFrame 기준)\n",
    "null_counts = df_monthly.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_monthly.columns\n",
    "])\n",
    "null_counts.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3029cb6a-1ce6-4760-bd0d-bedb4ff1113d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_monthly.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://1dt-2nd-team1-postgres.postgres.database.azure.com:5432/postgres\") \\\n",
    "    .option(\"dbtable\", \"silver.silver_monthly_202307_202506\") \\\n",
    "    .option(\"user\", \"azureuser\") \\\n",
    "    .option(\"password\", \"asdASD123!@#\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"sslmode\", \"require\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a848b5a-0395-48d4-b7ba-446789119576",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 시간대별 합계차료 새로운 df만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "532fa350-9c56-4a65-af1a-0b84d4cc5ddd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 시간대(hour_of_day)별 전체 합계 집계 (행 24개)\n",
    "df_hourly_by_hour = df_hourly.groupBy(\"hour_of_day\").agg(\n",
    "    F.sum(\"flight_arrival\").alias(\"sum_flight_arrival\"),\n",
    "    F.sum(\"flight_departure\").alias(\"sum_flight_departure\"),\n",
    "    F.sum(\"flight_total\").alias(\"sum_flight_total\"),\n",
    "    F.sum(\"passenger_arrival\").alias(\"sum_passenger_arrival\"),\n",
    "    F.sum(\"passenger_departure\").alias(\"sum_passenger_departure\"),\n",
    "    F.sum(\"passenger_total\").alias(\"sum_passenger_total\"),\n",
    "    F.sum(\"cargo_arrival\").alias(\"sum_cargo_arrival\"),\n",
    "    F.sum(\"cargo_departure\").alias(\"sum_cargo_departure\"),\n",
    "    F.sum(\"cargo_total\").alias(\"sum_cargo_total\")\n",
    ").orderBy(\"hour_of_day\")\n",
    "\n",
    "# 결과 확인 (행 24개, 컬럼은 합계)\n",
    "display(df_hourly_by_hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "777dc45b-0da5-4e1f-b1ef-8e7ac3a49e8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_hourly_by_hour.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://1dt-2nd-team1-postgres.postgres.database.azure.com:5432/postgres\") \\\n",
    "    .option(\"dbtable\", \"silver.silver_hourly_by_hour_202307_202506\") \\\n",
    "    .option(\"user\", \"azureuser\") \\\n",
    "    .option(\"password\", \"asdASD123!@#\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"sslmode\", \"require\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66c7bf10-b414-477a-9829-d927b6d9f61b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 간단 분석?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41881ebb-eea5-4ac9-aee3-335428d797c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks/PySpark 환경에서 시간대별 혼잡도 대시보드 시각화 (2x2 그래프)\n",
    "# - 주석 및 설명은 한글, 그래프 내 제목/축/라벨은 영어로만 표기 (한글 깨짐 방지)\n",
    "\n",
    "from pyspark.sql import functions as F, Window\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 파생 컬럼 계산 (혼잡도, 평균 승객 등)\n",
    "df = df_hourly_by_hour.withColumn(\n",
    "    \"avg_passenger_per_flight\",\n",
    "    F.col(\"sum_passenger_total\") / F.col(\"sum_flight_total\")\n",
    ")\n",
    "\n",
    "# 전체 평균 항공편 수 (혼잡도 지표용)\n",
    "avg_flight_total = df.agg(F.avg(\"sum_flight_total\")).first()[0]\n",
    "df = df.withColumn(\n",
    "    \"congestion_index\",\n",
    "    F.col(\"sum_flight_total\") / F.lit(avg_flight_total)\n",
    ")\n",
    "\n",
    "# 혼잡도 상위 20% 시간대 피크 플래그\n",
    "window = Window.orderBy(F.desc(\"congestion_index\"))\n",
    "row_count = df.count()\n",
    "top_n = int(row_count * 0.2)\n",
    "df = df.withColumn(\n",
    "    \"peak_time_flag\",\n",
    "    F.when(F.row_number().over(window) <= top_n, 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# 2. Pandas 변환 (시각화용)\n",
    "pdf = df.orderBy(\"hour_of_day\").toPandas()\n",
    "\n",
    "# 3. 2x2 그래프 그리기 (그래프 내 모든 텍스트는 영어로)\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 10))\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.25)\n",
    "\n",
    "# (1) Total flights per hour (bar)\n",
    "axs[0, 0].bar(pdf[\"hour_of_day\"], pdf[\"sum_flight_total\"], color=\"#4e79a7\")\n",
    "axs[0, 0].set_title(\"Total Flights by Hour\")\n",
    "axs[0, 0].set_xlabel(\"Hour of Day\")\n",
    "axs[0, 0].set_ylabel(\"Flights\")\n",
    "\n",
    "# (2) Congestion index (line)\n",
    "axs[0, 1].plot(pdf[\"hour_of_day\"], pdf[\"congestion_index\"], marker='o', color=\"#f28e2b\")\n",
    "axs[0, 1].set_title(\"Congestion Index by Hour\")\n",
    "axs[0, 1].set_xlabel(\"Hour of Day\")\n",
    "axs[0, 1].set_ylabel(\"Congestion (mean=1)\")\n",
    "\n",
    "# (3) Average passengers per flight (line)\n",
    "axs[1, 0].plot(pdf[\"hour_of_day\"], pdf[\"avg_passenger_per_flight\"], marker='s', color=\"#76b7b2\")\n",
    "axs[1, 0].set_title(\"Avg Passengers per Flight\")\n",
    "axs[1, 0].set_xlabel(\"Hour of Day\")\n",
    "axs[1, 0].set_ylabel(\"Avg Passengers\")\n",
    "\n",
    "# (4) Peak time flag (bar)\n",
    "axs[1, 1].bar(pdf[\"hour_of_day\"], pdf[\"peak_time_flag\"], color=\"#e15759\")\n",
    "axs[1, 1].set_title(\"Peak Time Flag (Top 20%)\")\n",
    "axs[1, 1].set_xlabel(\"Hour of Day\")\n",
    "axs[1, 1].set_ylabel(\"Peak Time (1=Top 20%)\")\n",
    "\n",
    "plt.suptitle(\"Hourly Airport Congestion Dashboard\", fontsize=18, fontweight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91983470-0552-4f00-a6fa-23cfd11efc31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 시간대별 공항 혼잡도 및 운영 인사이트\n",
    "\n",
    "## 1. 항공편 운항량과 혼잡 패턴\n",
    "- **항공편 총 운항량**은 오전 6시부터 급격히 증가하여 7 ~ 9시, 11~17시 사이에 최고치를 기록합니다.\n",
    "- **16~17시**가 가장 많은 항공편이 운항되는 피크 시간대입니다.\n",
    "- **새벽(0 ~3시), 밤(22 ~23시)**에는 항공편이 적어 혼잡도가 낮습니다.\n",
    "\n",
    "## 2. 승객 이동량\n",
    "- **승객 총 이동량**은 7시부터 급증, 8 ~10시, 15 ~18시 사이에 매우 높음.\n",
    "- **16~17시**에는 약 900만 명 이상의 승객 이동.\n",
    "- **새벽(0~3시)**는 승객 수가 적어 혼잡이 덜함.\n",
    "\n",
    "## 3. 화물 이동량\n",
    "- **화물 이동량**도 항공편·승객 패턴과 유사, 7 ~9시, 15 ~17시 집중.\n",
    "- **7시, 16~17시**에 화물 이동량이 가장 많음.\n",
    "\n",
    "## 4. 항공편당 평균 승객 수\n",
    "- **평균 120~130명**(6 ~21시), 새벽(0  ~3시)은 90 ~110명으로 낮음.\n",
    "\n",
    "## 5. 혼잡도 지수 및 피크타임\n",
    "- **혼잡도 지수**는 8~17시에 1 이상(평균 초과), 피크 집중.\n",
    "- **피크타임 플래그(상위 20%)**: 8~17시 집중 → 운영상 최우선 관리 필요.\n",
    "\n",
    "---\n",
    "\n",
    "## 운영 및 관리 시사점\n",
    "\n",
    "- **오전 8시~오후 5시**: 인력·시설 집중 배치 필수 (혼잡 절정)\n",
    "- **새벽/야간(0 ~4시, 22 ~23시)**: 자원 효율화, 비용 절감 가능\n",
    "- **피크타임 자동 탐지**로 실시간 대응 및 서비스 품질 향상\n",
    "- **시간대별 수요 예측**을 통한 스케줄·화물 처리 최적화\n",
    "\n",
    "---\n",
    "\n",
    "## 시간대별 요약 표 (예시)\n",
    "\n",
    "| 시간대 (hour_of_day) | 총 항공편 수 | 총 승객 수   | 총 화물량 | 평균 승객/항공편 | 혼잡도 지수 | 피크타임 여부 |\n",
    "|---------------------|-------------|-------------|----------|-----------------|------------|--------------|\n",
    "| 0                   | 12,732      | 1,338,403   | 264,399  | 약 105          | 낮음 (<1)  | 0            |\n",
    "| 8                   | 45,284      | 7,674,693   | 297,411  | 약 169          | 높음 (>2)  | 1            |\n",
    "| 16                  | 46,628      | 8,983,528   | 278,253  | 약 193          | 최고       | 1            |\n",
    "| 23                  | 21,417      | 2,597,710   | 397,075  | 약 121          | 낮음 (~1)  | 0            |\n",
    "\n",
    "*전체 시간대 그래프 및 상세 데이터는 별도 참고*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a520e39b-8936-4109-bdfa-ac9ea7ea30c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 시간대별 혼잡도 대시보드 4개 그래프: 제목 및 한글 설명\n",
    "\n",
    "아래는 2x2 형태로 시각화된 각 그래프의 한글 제목과 상세 설명입니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. (왼쪽 위) 시간대별 항공편 총합\n",
    "\n",
    "**제목:**  \n",
    "시간대별 항공편 총합\n",
    "\n",
    "**설명:**  \n",
    "- 0시부터 23시까지 각 시간대별로 운항된 항공편(도착+출발) 총합을 막대그래프로 나타냅니다.\n",
    "- 어느 시간대에 항공편이 가장 많이 몰려 있는지, 새벽·야간에는 얼마나 적은지 한눈에 비교할 수 있습니다.\n",
    "- 공항의 운영 피크 시간대와 비혼잡 시간대를 파악하는 데 유용합니다.\n",
    "s\n",
    "---\n",
    "\n",
    "## 2. (오른쪽 위) 시간대별 혼잡도 지수\n",
    "\n",
    "**제목:**  \n",
    "시간대별 혼잡도 지수\n",
    "\n",
    "**설명:**  \n",
    "- 각 시간대의 항공편 총합을 전체 평균과 비교해 혼잡도를 지수(평균=1)로 나타낸 선그래프입니다.\n",
    "- 1보다 높으면 평균보다 혼잡한 시간대, 1보다 낮으면 한산한 시간대를 의미합니다.\n",
    "- 혼잡도가 가장 높은 시간대와 상대적으로 여유로운 시간대를 직관적으로 확인할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. (왼쪽 아래) 항공편 1대당 평균 승객 수\n",
    "\n",
    "**제목:**  \n",
    "항공편 1대당 평균 승객 수\n",
    "\n",
    "**설명:**  \n",
    "- 각 시간대별로 항공편 1대당 평균적으로 몇 명의 승객이 탑승하는지 선그래프로 보여줍니다.\n",
    "- 시간대별로 승객 효율성(적재율)이 어떻게 달라지는지, 새벽·야간과 주간의 차이를 파악할 수 있습니다.\n",
    "- 항공사·운영사 입장에서 서비스 효율성이나 수요 예측에 참고할 수 있는 지표입니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. (오른쪽 아래) 피크타임 플래그 (상위 20%)\n",
    "\n",
    "**제목:**  \n",
    "피크타임 플래그 (상위 20%)\n",
    "\n",
    "**설명:**  \n",
    "- 혼잡도 지수 기준 상위 20%에 해당하는 시간대를 막대그래프로 표시합니다.\n",
    "- 피크타임(1)과 비피크타임(0)을 구분하여, 운영상 특별 관리가 필요한 시간대를 한눈에 볼 수 있습니다.\n",
    "- 인력 배치, 시설 운영, 혼잡 안내 등 실무적 의사결정에 바로 활용할 수 있습니다.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "시간대 및 월별_정적데이터_출력제거",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}